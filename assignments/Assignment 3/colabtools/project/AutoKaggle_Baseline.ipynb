{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoKaggle-Baseline.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "AgrdCLpEl5N4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "3da58692-3fe9-4275-f5ff-34f0c281d700"
      },
      "cell_type": "code",
      "source": [
        "# Add all relevant imports here\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn.svm as svm\n",
        "import sklearn.tree as tree\n",
        "import sklearn.ensemble as ensemble\n",
        "import sklearn.neighbors as neighbors\n",
        "import sklearn.naive_bayes as naive_bayes\n",
        "import sklearn.linear_model as linear_model\n",
        "\n",
        "from sklearn import impute\n",
        "from sklearn import preprocessing as preproc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import accuracy_score, log_loss, mean_squared_error, mean_absolute_error, roc_curve, auc\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e455b242-ce83-4e19-8d5c-767553e2f927\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e455b242-ce83-4e19-8d5c-767553e2f927\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-85788565b960>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Unable to get property '_uploadFiles' of undefined or null reference"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hVstbfAemBxK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Accessing Google sheets\n",
        "!pip install --upgrade -q gspread\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "worksheet = gc.open('AutoKaggle').worksheet('Metadata')\n",
        "\n",
        "# get_all_values gives a list of rows\n",
        "_rows = worksheet.get_all_values()\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "rows = pd.DataFrame.from_records(_rows)\n",
        "\n",
        "new_header = rows.iloc[0] #grab the first row for the header\n",
        "rows = rows[1:] #take the data less the header row\n",
        "rows.columns = new_header #set the header row as the df header"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ImeUr018mDxJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def alpha_to_number(alpha_key):\n",
        "  return sum([(ord(alpha)-64)*(26**ind) for ind, alpha in enumerate(list(alpha_key)[::-1])]) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "f7mlr50ymaKB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parseMetaData(row_id):\n",
        "  \n",
        "  # Parse data from MetaData for each row\n",
        "  column_key = {'name': 'C', 'columns': 'W', 'estimator_func_call': 'AU', 'target_name': 'AC', 'output_type': 'AA', 'performance_metric': 'BB', 'feature_selector': 'AL'}\n",
        "  column_key = dict(map(lambda kv: (kv[0], alpha_to_number(kv[1])), column_key.items()))\n",
        "  \n",
        "  metadata['competition_name'] = rows.loc[row_id][column_key['name']]\n",
        "  metadata['estimator'] = rows.loc[row_id][column_key['estimator_func_call']]\n",
        "  metadata['target_column'] = rows.loc[row_id][column_key['target_name']]\n",
        "  metadata['output_type'] = rows.loc[row_id][column_key['output_type']].split(',')\n",
        "  metadata['metric'] = rows.loc[row_id][column_key['performance_metric']]\n",
        "  metadata['feature_selector'] = rows.loc[row_id][column_key['feature_selector']]\n",
        "  columns = rows.loc[row_id][column_key['columns']]\n",
        "\n",
        "  # Parse column information \n",
        "  numeric_columns = []\n",
        "  unwanted_columns = []\n",
        "  categorical_columns = []\n",
        "  columns_data = [x.strip() for x in columns[1:-1].split(';')]\n",
        "  for ind, val in enumerate(columns_data):\n",
        "    if ind%3 == 2:\n",
        "      if (val == \"numeric\" or val == \"integer\" or val == \"real\"):\n",
        "        numeric_columns.append(columns_data[ind-1])\n",
        "      elif val == \"categorical\":\n",
        "        categorical_columns.append(columns_data[ind-1])\n",
        "      elif val == \"unwanted\" or val == \"string\" or val == 'dateTime':\n",
        "        unwanted_columns.append(columns_data[ind-1])\n",
        "    else:\n",
        "      pass\n",
        "    \n",
        "  metadata['numeric_columns'] = numeric_columns\n",
        "  metadata['unwanted_columns'] = unwanted_columns\n",
        "  metadata['categorical_columns'] = categorical_columns\n",
        "  \n",
        "  # Remove target from features columns\n",
        "  if metadata['target_column'] in metadata['numeric_columns']:\n",
        "    metadata['numeric_columns'].remove(metadata['target_column'])\n",
        "  if metadata['target_column'] in metadata['categorical_columns']:\n",
        "    metadata['categorical_columns'].remove(metadata['target_column'])\n",
        "  if metadata['target_column'] in metadata['unwanted_columns']:\n",
        "    metadata['unwanted_columns'].remove(metadata['target_column'])\n",
        "  \n",
        "  print(metadata['competition_name'])\n",
        "  print(metadata['numeric_columns'])\n",
        "  print(metadata['categorical_columns'])\n",
        "  print(metadata['unwanted_columns'])\n",
        "  print(metadata['target_column'])\n",
        "  print(metadata['metric'])\n",
        "  print(metadata['feature_selector'])\n",
        "  print(metadata['estimator'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hm1kNv9qmoh2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We have put some fixed values here for feature_selectors,estimators etc\n",
        "# TODO: Perform reading cells for the following objects from Metadata sheet\n",
        "# TODO: Sometimes you may need to add more objects so your pipeline works efficiently\n",
        "# TODO: The data in the metadata sheet might not be completely correct, so correct it accordingly\n",
        "# TODO: The data in the metadata sheet might not be completely sufficient, let us know so wen can add new column. DO NOT ADD NEW COLUMNS ON YOUR OWN\n",
        "\n",
        "# You can see that the column W i.e `columns [index;name;type;...] for type use categorical or numerical has this information` has the type information.\n",
        "# But on closer observation this might not be completely useful. For example the type for 'Sex' can be string(that is how the data is in the dataset) but for \n",
        "# our needs its a categorical value on which we need to do one hot encoding\n",
        "# Similarly the passengerid is a numeric value which is like a unique id. We don't do normalization on it\n",
        "# Because of this reason we need to modify this column appropriately\n",
        "\n",
        "# For now we decided the types of columns will be as follows\n",
        "# numeric(integer, real) - represented as `numerical` - These columns will be normalized\n",
        "# categorical - represented as `categorical` - These values will be encoded using one-hot encoding\n",
        "# string - represted as `string`\n",
        "# dateTime - represented as `dateTime`\n",
        "# If new types are required let us know. So everyone will be using similar tags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "s25lnX0emrk1",
        "outputId": "7ac57e36-008e-43fe-afbb-936ac24d248f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ATHkPGgHmty1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocessing(train_df):\n",
        "  \n",
        "  # drop unwanted columns\n",
        "  if metadata['unwanted_columns']:\n",
        "    train_df.drop(metadata['unwanted_columns'], axis=1, inplace=True)\n",
        "  \n",
        "  X = train_df.drop(metadata['target_column'], 1)\n",
        "  y = train_df[metadata['target_column']]\n",
        "  \n",
        "  # treat missing values\n",
        "  pd.set_option('mode.chained_assignment', None) # used to subside the panda's chain assignment warning\n",
        "  imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "  for col in metadata['numeric_columns']:\n",
        "    X[[col]] = imp.fit_transform(X[[col]])\n",
        "    \n",
        "  # Categorial transform  \n",
        "  for col in metadata['categorical_columns']:\n",
        "    col_dummies = pd.get_dummies(X[col], dummy_na=True)\n",
        "    X = pd.concat([X, col_dummies], axis=1)\n",
        "  X.drop(metadata['categorical_columns'], axis=1, inplace=True)\n",
        "  \n",
        "  # Feature normalization\n",
        "  X[metadata['numeric_columns']] = preproc.scale(X[metadata['numeric_columns']])\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "  \n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uQ0lsMYHm3Mz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Feature Extraction\n",
        "def feature_extraction():\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KyZcSB3cm5L8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Feature Selection\n",
        "def feature_selection(X_train, X_test, y_train, y_test):\n",
        "  \n",
        "  selector = eval(metadata['feature_selector'])\n",
        "  X_train = selector.fit_transform(X_train, y_train)\n",
        "  X_test = selector.fit_transform(X_test, y_test)\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yrDr_Qiom6xU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def estimation(X_train, X_test, y_train, y_test):\n",
        "  \n",
        "  model = eval(metadata['estimator'])\n",
        "    \n",
        "  model.fit(X_train, y_train)\n",
        "  predict = model.predict(X_test)\n",
        "  if metadata['metric'] == \"rmse\":\n",
        "    error = np.sqrt(mean_squared_error(y_test, predict))\n",
        "  elif metadata['metric'] == \"accuracy\":\n",
        "    error = accuracy_score(y_test, predict)\n",
        "  elif metadata['metric'] == \"auc\":\n",
        "    fpr, tpr, _ = roc_curve(y_test, predict)\n",
        "    error = auc(fpr, tpr)\n",
        "  print(error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9UmYmuaQm83o",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Postprocessing\n",
        "def postprocessing():\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cLucc0D-m-uw",
        "outputId": "53870fe4-018c-4669-9641-2bf99dfb2fbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "cell_type": "code",
      "source": [
        "row_ids = [11]\n",
        "metadata = {}\n",
        "\n",
        "# Set your current working directory\n",
        "cwd = \"/gdrive/Shared With Me/Introduction to Data Science Spring 2019 Term Project/vv913/\"\n",
        "\n",
        "for row_id in row_ids:\n",
        "  \n",
        "  # Parsing MetaData updates the metadata dict\n",
        "  metadata.clear()\n",
        "  print(\"************************************************************\")\n",
        "  parseMetaData(row_id)\n",
        "  competition_dir = cwd + metadata['competition_name'] + '/data/trainData.csv'\n",
        "\n",
        "  train_df = pd.read_csv(competition_dir)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = preprocessing(train_df)\n",
        "  if metadata['feature_selector']:\n",
        "     X_train, X_test, y_train, y_test = feature_selection(X_train, X_test, y_train, y_test)\n",
        "  estimation(X_train, X_test, y_train, y_test)\n",
        "  print(\"************************************************************\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "************************************************************\n",
            "talkingdata-adtracking-fraud-detection\n",
            "['ip', 'app', 'device', 'os', 'channel']\n",
            "[]\n",
            "['click_time', 'attributed_time']\n",
            "is_attributed\n",
            "auc\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-63545764bb9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mcompetition_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcwd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'competition_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/data/trainData.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompetition_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/gdrive/Shared With Me/Introduction to Data Science Spring 2019 Term Project/vv913/talkingdata-adtracking-fraud-detection/data/trainData.csv' does not exist: b'/gdrive/Shared With Me/Introduction to Data Science Spring 2019 Term Project/vv913/talkingdata-adtracking-fraud-detection/data/trainData.csv'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "o9E013XrnAiv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}