{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AgrdCLpEl5N4"
   },
   "outputs": [],
   "source": [
    "# Add all relevant imports here\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.svm as svm\n",
    "import sklearn.tree as tree\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.neighbors as neighbors\n",
    "import sklearn.naive_bayes as naive_bayes\n",
    "import sklearn.linear_model as linear_model\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing as preproc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score, log_loss, mean_squared_error, mean_absolute_error, roc_curve, auc\n",
    "\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hVstbfAemBxK"
   },
   "outputs": [],
   "source": [
    "# Accessing Google sheets\n",
    "!pip install --upgrade -q gspread\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "import gspread\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
    "\n",
    "worksheet = gc.open('AutoKaggle').worksheet('Metadata')\n",
    "\n",
    "# get_all_values gives a list of rows\n",
    "_rows = worksheet.get_all_values()\n",
    "\n",
    "# Convert to a DataFrame and render.\n",
    "import pandas as pd\n",
    "rows = pd.DataFrame.from_records(_rows)\n",
    "\n",
    "new_header = rows.iloc[0] #grab the first row for the header\n",
    "rows = rows[1:] #take the data less the header row\n",
    "rows.columns = new_header #set the header row as the df header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ImeUr018mDxJ"
   },
   "outputs": [],
   "source": [
    "def alpha_to_number(alpha_key):\n",
    "  return sum([(ord(alpha)-64)*(26**ind) for ind, alpha in enumerate(list(alpha_key)[::-1])]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7mlr50ymaKB"
   },
   "outputs": [],
   "source": [
    "def parseMetaData(row_id):\n",
    "  \n",
    "  # Parse data from MetaData for each row\n",
    "  column_key = {'name': 'C', 'columns': 'W', 'estimator_func_call': 'AU', 'target_name': 'AC', 'output_type': 'AA', 'performance_metric': 'BB', 'feature_selector': 'AL'}\n",
    "  column_key = dict(map(lambda kv: (kv[0], alpha_to_number(kv[1])), column_key.items()))\n",
    "  \n",
    "  metadata['competition_name'] = rows.loc[row_id][column_key['name']]\n",
    "  metadata['estimator'] = rows.loc[row_id][column_key['estimator_func_call']]\n",
    "  metadata['target_column'] = rows.loc[row_id][column_key['target_name']]\n",
    "  metadata['output_type'] = rows.loc[row_id][column_key['output_type']].split(',')\n",
    "  metadata['metric'] = rows.loc[row_id][column_key['performance_metric']]\n",
    "  metadata['feature_selector'] = rows.loc[row_id][column_key['feature_selector']]\n",
    "  columns = rows.loc[row_id][column_key['columns']]\n",
    "\n",
    "  # Parse column information \n",
    "  numeric_columns = []\n",
    "  unwanted_columns = []\n",
    "  categorical_columns = []\n",
    "  columns_data = [x.strip() for x in columns[1:-1].split(';')]\n",
    "  for ind, val in enumerate(columns_data):\n",
    "    if ind%3 == 2:\n",
    "      if (val == \"numeric\" or val == \"integer\" or val == \"real\"):\n",
    "        numeric_columns.append(columns_data[ind-1])\n",
    "      elif val == \"categorical\":\n",
    "        categorical_columns.append(columns_data[ind-1])\n",
    "      elif val == \"unwanted\" or val == \"string\" or val == 'dateTime':\n",
    "        unwanted_columns.append(columns_data[ind-1])\n",
    "    else:\n",
    "      pass\n",
    "    \n",
    "  metadata['numeric_columns'] = numeric_columns\n",
    "  metadata['unwanted_columns'] = unwanted_columns\n",
    "  metadata['categorical_columns'] = categorical_columns\n",
    "  \n",
    "  # Remove target from features columns\n",
    "  if metadata['target_column'] in metadata['numeric_columns']:\n",
    "    metadata['numeric_columns'].remove(metadata['target_column'])\n",
    "  if metadata['target_column'] in metadata['categorical_columns']:\n",
    "    metadata['categorical_columns'].remove(metadata['target_column'])\n",
    "  if metadata['target_column'] in metadata['unwanted_columns']:\n",
    "    metadata['unwanted_columns'].remove(metadata['target_column'])\n",
    "  \n",
    "  print(metadata['competition_name'])\n",
    "  print(metadata['numeric_columns'])\n",
    "  print(metadata['categorical_columns'])\n",
    "  print(metadata['unwanted_columns'])\n",
    "  print(metadata['target_column'])\n",
    "  print(metadata['metric'])\n",
    "  print(metadata['feature_selector'])\n",
    "  print(metadata['estimator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hm1kNv9qmoh2"
   },
   "outputs": [],
   "source": [
    "# We have put some fixed values here for feature_selectors,estimators etc\n",
    "# TODO: Perform reading cells for the following objects from Metadata sheet\n",
    "# TODO: Sometimes you may need to add more objects so your pipeline works efficiently\n",
    "# TODO: The data in the metadata sheet might not be completely correct, so correct it accordingly\n",
    "# TODO: The data in the metadata sheet might not be completely sufficient, let us know so wen can add new column. DO NOT ADD NEW COLUMNS ON YOUR OWN\n",
    "\n",
    "# You can see that the column W i.e `columns [index;name;type;...] for type use categorical or numerical has this information` has the type information.\n",
    "# But on closer observation this might not be completely useful. For example the type for 'Sex' can be string(that is how the data is in the dataset) but for \n",
    "# our needs its a categorical value on which we need to do one hot encoding\n",
    "# Similarly the passengerid is a numeric value which is like a unique id. We don't do normalization on it\n",
    "# Because of this reason we need to modify this column appropriately\n",
    "\n",
    "# For now we decided the types of columns will be as follows\n",
    "# numeric(integer, real) - represented as `numerical` - These columns will be normalized\n",
    "# categorical - represented as `categorical` - These values will be encoded using one-hot encoding\n",
    "# string - represted as `string`\n",
    "# dateTime - represented as `dateTime`\n",
    "# If new types are required let us know. So everyone will be using similar tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 69258,
     "status": "ok",
     "timestamp": 1555896332489,
     "user": {
      "displayName": "Divyansh Khanna",
      "photoUrl": "https://lh6.googleusercontent.com/-ai7TE5M_7qM/AAAAAAAAAAI/AAAAAAAAAEo/vjeNX_rFbzk/s64/photo.jpg",
      "userId": "08670235296186319619"
     },
     "user_tz": 240
    },
    "id": "s25lnX0emrk1",
    "outputId": "4ec24a44-9ed6-42e8-f8b5-fdc3b142e70b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATHkPGgHmty1"
   },
   "outputs": [],
   "source": [
    "def preprocessing(train_df):\n",
    "  \n",
    "  # drop unwanted columns\n",
    "  if metadata['unwanted_columns']:\n",
    "    train_df.drop(metadata['unwanted_columns'], axis=1, inplace=True)\n",
    "  \n",
    "  X = train_df.drop(metadata['target_column'], 1)\n",
    "  y = train_df[metadata['target_column']]\n",
    "  \n",
    "  # treat missing values\n",
    "  pd.set_option('mode.chained_assignment', None) # used to subside the panda's chain assignment warning\n",
    "  imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "  for col in metadata['numeric_columns']:\n",
    "    X[[col]] = imp.fit_transform(X[[col]])\n",
    "    \n",
    "  # Categorial transform  \n",
    "  for col in metadata['categorical_columns']:\n",
    "    col_dummies = pd.get_dummies(X[col], dummy_na=True)\n",
    "    X = pd.concat([X, col_dummies], axis=1)\n",
    "  X.drop(metadata['categorical_columns'], axis=1, inplace=True)\n",
    "  \n",
    "  # Feature normalization\n",
    "  X[metadata['numeric_columns']] = preproc.scale(X[metadata['numeric_columns']])\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "  \n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQ0lsMYHm3Mz"
   },
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "def feature_extraction():\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyZcSB3cm5L8"
   },
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "def feature_selection(X_train, X_test, y_train, y_test):\n",
    "  \n",
    "  selector = eval(metadata['feature_selector'])\n",
    "  X_train = selector.fit_transform(X_train, y_train)\n",
    "  X_test = selector.fit_transform(X_test, y_test)\n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrDr_Qiom6xU"
   },
   "outputs": [],
   "source": [
    "def estimation(X_train, X_test, y_train, y_test):\n",
    "  \n",
    "  model = eval(metadata['estimator'])\n",
    "    \n",
    "  model.fit(X_train, y_train)\n",
    "  predict = model.predict(X_test)\n",
    "  if metadata['metric'] == \"rmse\":\n",
    "    error = np.sqrt(mean_squared_error(y_test, predict))\n",
    "  elif metadata['metric'] == \"accuracy\":\n",
    "    error = accuracy_score(y_test, predict)\n",
    "  elif metadata['metric'] == \"auc\":\n",
    "    fpr, tpr, _ = roc_curve(y_test, predict)\n",
    "    error = auc(fpr, tpr)\n",
    "  print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UmYmuaQm83o"
   },
   "outputs": [],
   "source": [
    "# Postprocessing\n",
    "def postprocessing():\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4083
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8797,
     "status": "ok",
     "timestamp": 1555896351772,
     "user": {
      "displayName": "Divyansh Khanna",
      "photoUrl": "https://lh6.googleusercontent.com/-ai7TE5M_7qM/AAAAAAAAAAI/AAAAAAAAAEo/vjeNX_rFbzk/s64/photo.jpg",
      "userId": "08670235296186319619"
     },
     "user_tz": 240
    },
    "id": "cLucc0D-m-uw",
    "outputId": "eab0a878-ee53-4e1f-c8d3-0ff3ddd85108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "restaurant-revenue-prediction\n",
      "['Id', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15', 'P16', 'P17', 'P18', 'P19', 'P20', 'P21', 'P22', 'P23', 'P24', 'P25', 'P26', 'P27', 'P28', 'P29', 'P30', 'P31', 'P32', 'P33', 'P34', 'P35', 'P36', 'P37']\n",
      "['City Group', 'Type']\n",
      "['Open Date', 'City']\n",
      "revenue\n",
      "rmse\n",
      "\n",
      "ensemble.RandomForestRegressor(n_estimators=1000, max_features=2)\n",
      "2336850.649006377\n",
      "************************************************************\n",
      "************************************************************\n",
      "titanic\n",
      "['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "['Sex', 'Embarked']\n",
      "['Name', 'Ticket', 'Cabin']\n",
      "Survived\n",
      "accuracy\n",
      "\n",
      "svm.SVC()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8251121076233184\n",
      "************************************************************\n",
      "************************************************************\n",
      "restaurant-revenue-prediction\n",
      "['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15', 'P16', 'P17', 'P18', 'P19', 'P20', 'P21', 'P22', 'P23', 'P24', 'P25', 'P26', 'P27', 'P28', 'P29', 'P30', 'P31', 'P32', 'P33', 'P34', 'P35', 'P36', 'P37']\n",
      "['City Group', 'Type']\n",
      "['Id', 'Open Date', 'City']\n",
      "revenue\n",
      "rmse\n",
      "\n",
      "ensemble.RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=4,max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None, oob_score=False, random_state=2019, verbose=0, warm_start=False)\n",
      "3189151.84324473\n",
      "************************************************************\n",
      "************************************************************\n",
      "titanic\n",
      "['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "['Sex', 'Embarked']\n",
      "['Name', 'Ticket', 'Cabin']\n",
      "Survived\n",
      "accuracy\n",
      "SelectKBest(f_classif, k=10)\n",
      "ensemble.RandomForestClassifier(n_estimators=1000, min_samples_split=4, max_depth=8, class_weight={0:0.745,1:0.255})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [ 8 12] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8251121076233184\n",
      "************************************************************\n",
      "************************************************************\n",
      "house-prices-advanced-regression-techniques\n",
      "['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n",
      "['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
      "[]\n",
      "SalePrice\n",
      "rmse\n",
      "\n",
      "ensemble.RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,max_features='auto', max_leaf_nodes=None,min_impurity_decrease=0.0, min_impurity_split=None,min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,oob_score=False, random_state=2019, verbose=0, warm_start=False)\n",
      "31898.342282070193\n",
      "************************************************************\n",
      "************************************************************\n",
      "titanic\n",
      "['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "['Sex', 'Embarked']\n",
      "['Name', 'Ticket', 'Cabin']\n",
      "Survived\n",
      "accuracy\n",
      "SelectKBest(f_classif, k=10)\n",
      "linear_model.LogisticRegression()\n",
      "0.5695067264573991\n",
      "************************************************************\n",
      "************************************************************\n",
      "titanic\n",
      "['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "['Sex', 'Embarked']\n",
      "['Name', 'Ticket', 'Cabin']\n",
      "Survived\n",
      "accuracy\n",
      "SelectKBest(f_classif, k=10)\n",
      "neighbors.KNeighborsClassifier(n_neighbors = 3)\n",
      "0.4439461883408072\n",
      "************************************************************\n",
      "************************************************************\n",
      "titanic\n",
      "['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "['Sex', 'Embarked']\n",
      "['Name', 'Ticket', 'Cabin']\n",
      "Survived\n",
      "accuracy\n",
      "SelectKBest(f_classif, k=10)\n",
      "naive_bayes.GaussianNB()\n",
      "0.672645739910314\n",
      "************************************************************\n",
      "************************************************************\n",
      "titanic\n",
      "['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "['Sex', 'Embarked']\n",
      "['Name', 'Ticket', 'Cabin']\n",
      "Survived\n",
      "accuracy\n",
      "SelectKBest(f_classif, k=10)\n",
      "linear_model.Perceptron()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [ 8 12] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7668161434977578\n",
      "************************************************************\n",
      "************************************************************\n",
      "titanic\n",
      "['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "['Sex', 'Embarked']\n",
      "['Name', 'Ticket', 'Cabin']\n",
      "Survived\n",
      "accuracy\n",
      "SelectKBest(f_classif, k=10)\n",
      "svm.LinearSVC()\n",
      "0.7757847533632287\n",
      "************************************************************\n",
      "************************************************************\n",
      "titanic\n",
      "['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "['Sex', 'Embarked']\n",
      "['Name', 'Ticket', 'Cabin']\n",
      "Survived\n",
      "accuracy\n",
      "SelectKBest(f_classif, k=10)\n",
      "linear_model.SGDClassifier()\n",
      "0.3811659192825112\n",
      "************************************************************\n",
      "************************************************************\n",
      "titanic\n",
      "['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "['Sex', 'Embarked']\n",
      "['Name', 'Ticket', 'Cabin']\n",
      "Survived\n",
      "accuracy\n",
      "SelectKBest(f_classif, k=10)\n",
      "tree.DecisionTreeClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [ 8 12] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [ 8 12] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34080717488789236\n",
      "************************************************************\n",
      "************************************************************\n",
      "titanic\n",
      "['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "['Sex', 'Embarked']\n",
      "['Name', 'Ticket', 'Cabin']\n",
      "Survived\n",
      "accuracy\n",
      "SelectKBest(f_classif, k=10)\n",
      "ensemble.RandomForestClassifier(n_estimators=100)\n",
      "0.5919282511210763\n",
      "************************************************************\n",
      "************************************************************\n",
      "amazon-employee-access-challenge\n",
      "['RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2', 'ROLE_DEPTNAME', 'ROLE_TITLE', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY', 'ROLE_CODE']\n",
      "[]\n",
      "[]\n",
      "ACTION\n",
      "auc\n",
      "\n",
      "linear_model.LogisticRegression(C=3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [8] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.5\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "row_ids = [449, 297, 369, 6, 507, 508, 509, 510, 511, 512, 513, 514, 515, 142]\n",
    "metadata = {}\n",
    "\n",
    "# Set your current working directory\n",
    "cwd = \"/gdrive/My Drive/Introduction to Data Science Spring 2019 Term Project/Baseline/\"\n",
    "\n",
    "for row_id in row_ids:\n",
    "  \n",
    "  # Parsing MetaData updates the metadata dict\n",
    "  metadata.clear()\n",
    "  print(\"************************************************************\")\n",
    "  parseMetaData(row_id)\n",
    "  competition_dir = cwd + metadata['competition_name'] + '/data/trainData.csv'\n",
    "\n",
    "  train_df = pd.read_csv(competition_dir)\n",
    "\n",
    "  X_train, X_test, y_train, y_test = preprocessing(train_df)\n",
    "  if metadata['feature_selector']:\n",
    "     X_train, X_test, y_train, y_test = feature_selection(X_train, X_test, y_train, y_test)\n",
    "  estimation(X_train, X_test, y_train, y_test)\n",
    "  print(\"************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9E013XrnAiv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AutoKaggle-Baseline.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
